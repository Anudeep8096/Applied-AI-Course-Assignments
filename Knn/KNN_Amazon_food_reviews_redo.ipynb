{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory to save pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pickle_files'):\n",
    "    os.mkdir('pickle_files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to return np array form of the data passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_np_array(data):\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### X and y, before being passed to this function must be converted to numpy array or must be sparse matrices\\\n",
    "### for consistency throughout the program.\n",
    "\n",
    "### y will be a numpy vector because y-values originally are stored in a column of the original dataframe (ie, it\\\n",
    "### will be of type pd.Series. When converted into np-array, it will become a numpy 1D array, i.e a column vector)\n",
    "\n",
    "def train_test_splitter(X, y, test_size = 0.2):\n",
    "    train_size = 1 - test_size\n",
    "    \n",
    "    train_row_upper_index = round(train_size*X.shape[0])\n",
    "    test_row_lower_index = train_row_upper_index + 1\n",
    "    \n",
    "    if(X.ndim == 1):\n",
    "        X = X.reshape((X.shape[0], 1))\n",
    "    y = y.reshape((y.shape[0], 1)) # y is \n",
    "    \n",
    "    X_train = X[:train_row_upper_index + 1, :]\n",
    "    X_test = X[test_row_lower_index:, :]\n",
    "    \n",
    "    y_train = y[:train_row_upper_index + 1]\n",
    "    y_test = y[test_row_lower_index:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter (k) tuning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### upper_limit - the max value of k upto which checks have to be made.\n",
    "### returns the best 'k'.\n",
    "\n",
    "def tune_k(upper_limit, X_train, y_train, X_cv, y_cv, algorithm, save_name):\n",
    "    \n",
    "    best_k = None\n",
    "    f1score_max = 0\n",
    "    f1score = None\n",
    "    \n",
    "    for i in range(1, upper_limit, 2):\n",
    "#         print(i)\n",
    "        knn = KNeighborsClassifier(n_neighbors = i, algorithm = algorithm)\n",
    "        knn = knn.fit(X_train, y_train)\n",
    "        \n",
    "        with open('pickle_files/' + save_name, 'wb') as knn_pickle:\n",
    "            pickle.dump(knn, knn_pickle)\n",
    "        \n",
    "        y_pred = knn.predict(X_cv)\n",
    "        \n",
    "        f1score = f1_score(y_cv, y_pred)\n",
    "#         print('f1' + str(f1score))\n",
    "        \n",
    "        if f1score > f1score_max:\n",
    "            f1score_max = f1score\n",
    "            print('dd' + str(i))\n",
    "            best_k = i\n",
    "            with open('pickle_files/' + save_name, 'wb') as knn_pickle:\n",
    "                pickle.dump(knn, knn_pickle) ## if file already exists, overwrite it with the knn with best k\n",
    "            \n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = sqlite3.connect('database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read only those rows which have rating score != 3, because for this problem we assume those will be neutral \\\n",
    "### reviews\n",
    "df = pd.read_sql_query('select * from reviews where Score != 3', db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### taking only first 10k rows because processing large number of rows on my laptop is not possible\n",
    "df = df.iloc[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the ratings with 0 (for negative reviews) and 1 (for positive reviews).\n",
    "#### Score of  >3 has been considered as positive and a score of <3 has been taken as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     5\n",
       "7     5\n",
       "8     5\n",
       "9     5\n",
       "10    5\n",
       "11    5\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list(map(lambda x: 0 if x<3 else 1, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Score'].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Deduplication\n",
    "If a user id has multiple entries for the same timestamp, then it should be removed because it is likely that multiple entries at the same timestamp were for the same product of different variety which has a different product id than other variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset = ['UserId', 'Time']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_df = df.drop_duplicates(subset = ['UserId', 'Time'], inplace = False, keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extracting the data needed (corpus)\n",
    "#### And removing html and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = deduplicated_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset cleaners\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_html(sentence):\n",
    "    html_tag_re_obj = re.compile('<.*>?')\n",
    "    return re.sub(html_tag_re_obj, ' ', sentence)\n",
    "\n",
    "def remove_punctuations(sentence):\n",
    "    cleaned_sentence = re.sub(r'[^a-zA-Z]', r' ', sentence)\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for doc in corpus:\n",
    "    cleaned_doc_1 = remove_html(doc)\n",
    "    cleaned_doc_2 = remove_punctuations(doc)\n",
    "    cleaned_corpus.append(cleaned_doc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3544\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## Since the negative food reviews are likely to contain words like \"don't\", \"didn't\", etc that impart important\n",
    "## meaning to the review, we check if such words exist in the corpus that we have. If these words are in the corpus,\n",
    "## then they should not be in the list of stop words that we use for removing the stopwords from our corpus\n",
    "\n",
    "count = 0\n",
    "for doc in cleaned_corpus:\n",
    "    if \"not\" in doc:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for doc in cleaned_corpus:\n",
    "    if \"don't\" in doc:\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for doc in cleaned_corpus:\n",
    "    if \"didn't\" in doc:\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'not' in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,0,1,0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_corpus = corpus with docs having no stop words\n",
    "# doing with the sexy lambda expression\n",
    "\n",
    "filtered_corpus = list(map(lambda doc: ' '.join(list(filter(lambda word: True if word not in stopwords else False\\\n",
    "                                                            , doc.split()))), corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9473"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I bought several Vitality canned dog food products found good quality. The product looks like stew processed meat smells better. My Labrador finicky appreciates product better most.',\n",
       " 'Product arrived labeled Jumbo Salted Peanuts...the peanuts actually small sized unsalted. Not sure error vendor intended represent product \"Jumbo\".']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classical way of removing the lambda expressions\n",
    "### verified the output of lambda expression output with the output of following implementation, outputs are same\n",
    "# docs_without_stop_words = []\n",
    "# for i, doc in enumerate(corpus):\n",
    "#     non_stop_words_in_doc = []\n",
    "#     for word in doc.split():\n",
    "#         if word not in stopwords:\n",
    "#             non_stop_words_in_doc.append(word)\n",
    "            \n",
    "    \n",
    "#     docs_without_stop_words.append(' '.join(non_stop_words_in_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Stemming the words (SnowballStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_filtered_corpus = list(map(lambda doc: ' '.join(list(map(stemmer.stem, doc.split()))), corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have bought sever of the vital can dog food product and have found them all to be of good quality. the product look more like a stew than a process meat and it smell better. my labrador is finicki and she appreci this product better than most.',\n",
       " 'product arriv label as jumbo salt peanuts...th peanut were actual small size unsalted. not sure if this was an error or if the vendor intend to repres the product as \"jumbo\".',\n",
       " 'this is a confect that has been around a few centuries. it is a light, pillowi citrus gelatin with nut - in this case filberts. and it is cut into tini squar and then liber coat with powder sugar. and it is a tini mouth of heaven. not too chewy, and veri flavorful. i high recommend this yummi treat. if you are familiar with the stori of c.s. lewi \"the lion, the witch, and the wardrobe\" - this is the treat that seduc edmund into sell out his brother and sister to the witch.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_filtered_corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the dataset according to Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_df['Text'] = stemmed_filtered_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = deduplicated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df_sorted = working_df.sort_values(by = 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_filtered_corpus_sorted = working_df_sorted['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = deduplicated_df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9473,)\n",
      "(9473,)\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_filtered_corpus_sorted.shape, scores.shape, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review vectorization and training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making a numpy array for the stemmed_filtered_corpus_sorted and saving it in variable corpus so that writing\\\n",
    "### codes will be easier. converting scores to numpy array as well and saving it in a variable of same name.\n",
    "\n",
    "corpus = convert_to_np_array(stemmed_filtered_corpus_sorted)\n",
    "scores = convert_to_np_array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting corpus into train, cv, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nought, y_train_nought, X_test, y_test = train_test_splitter(corpus, scores, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_cv, y_cv = train_test_splitter(X_train_nought, y_train_nought, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words (CountVectorizer)\n",
    "##### Note: Vectorization must be done on training set only, not on test set or the cross validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pickle_files/bow_pickles'):\n",
    "    os.mkdir('pickle_files/bow_pickles')\n",
    "    \n",
    "if os.path.exists('pickle_files/bow_pickles/document_term_matrix.pkl'):\n",
    "    with open('pickle_files/bow_pickles/document_term_matrix.pkl', 'rb') as dtm_pickle:\n",
    "        X_train_bow = pickle.load(dtm_pickle)\n",
    "        \n",
    "else:\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    \n",
    "#     fit() method takes 1D array (m,). train_test_splitter() returns (m,n) array. ravel() converts it into (m,)\n",
    "    count_vectorizer = count_vectorizer.fit(X_train.ravel())\n",
    "    X_train_bow = count_vectorizer.transform(X_train.ravel()) # document_term_matrix is saved as X_train_bow\n",
    "    with open('pickle_files/bow_pickles/document_term_matrix.pkl', 'wb') as dtm_pickle:\n",
    "        pickle.dump(X_train_bow, dtm_pickle)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TfIdf (TfIdfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pickle_files/tfidf_pickles'):\n",
    "    os.mkdir('pickle_files/tfidf_pickles')\n",
    "    \n",
    "if os.path.exists('pickle_files/tfidf_pickles/document_term_matrix.pkl'):\n",
    "    with open('pickle_files/tfidf_pickles/document_term_matrix.pkl', 'rb') as dtm_pickle:\n",
    "        X_train_tfidf = pickle.load(dtm_pickle)\n",
    "        \n",
    "else:\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer = tfidf_vectorizer.fit(X_train.ravel())\n",
    "    X_train_tfidf = tfidf_vectorizer.transform(X_train.ravel())\n",
    "    with open('pickle_files/tfidf_pickles/document_term_matrix.pkl', 'wb') as dtm_pickle:\n",
    "        pickle.dump(X_train_tfidf, dtm_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pickle_files/word2vec_pickles/'):\n",
    "    os.mkdir('pickle_files/word2vec_pickles/')\n",
    "\n",
    "if os.path.exists('pickle_files/word2vec_pickles/w2v_model.pkl'):\n",
    "    with open('pickle_files/word2vec_pickles/w2v_model.pkl', 'rb') as w2v_pickle:\n",
    "        w2v = pickle.load(w2v_pickle)\n",
    "else:\n",
    "    X_train_for_Word2Vec = []\n",
    "    for sentence in X_train.ravel():\n",
    "        X_train_for_Word2Vec.append(sentence.split())\n",
    "    \n",
    "    w2v = Word2Vec(X_train_for_Word2Vec, min_count = 1, size = 50, workers = 4)\n",
    "    with open('pickle_files/word2vec_pickles/w2v_model.pkl', 'wb') as w2v_pickle:\n",
    "        pickle.dump(w2v, w2v_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Avg Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('pickle_files/word2vec_pickles/avgw2v.pkl'):\n",
    "    with open('pickle_files/word2vec_pickles/avgw2v.pkl', 'rb') as avgw2v_pickle:\n",
    "        X_train_avgw2v = pickle.load(avgw2v_pickle)\n",
    "\n",
    "else:\n",
    "    X_train_avgw2v = []\n",
    "    for sentence in X_train_for_Word2Vec:\n",
    "        sum_of_words = 0\n",
    "        for word in sentence:\n",
    "            sum_of_words += w2v.wv[word]\n",
    "        X_train_avgw2v.append(sum_of_words/len(sentence))\n",
    "        \n",
    "    with open('pickle_files/word2vec_pickles/avgw2v.pkl', 'wb') as avgw2v_pickle:\n",
    "        pickle.dump(X_train_avgw2v, avgw2v_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. TfIdf Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('pickle_files/word2vec_pickles/tfidfw2v.pkl'):\n",
    "    with open('pickle_files/word2vec_pickles/tfidfw2v.pkl', 'rb') as tfidfw2v_pickle:\n",
    "        X_train_tfidfw2v = pickle.load(tfidfw2v_pickle)\n",
    "\n",
    "else:\n",
    "    X_train_tfidfw2v = []\n",
    "    for sentence in X_train_for_Word2Vec:\n",
    "        tfidf_weighted_sum = 0\n",
    "        for word in sentence:\n",
    "            if word not in tfidf_vectorizer.vocabulary_ or word not in w2v.wv:\n",
    "                continue\n",
    "            tfidf_weighted_sum += tfidf_vectorizer.vocabulary_[word] * w2v.wv[word]\n",
    "        X_train_tfidfw2v.append(tfidf_weighted_sum)\n",
    "        with open('pickle_files/word2vec_pickles/tfidfw2v.pkl', 'wb') as tfidfw2v_pickle:\n",
    "            pickle.dump(X_train_tfidfw2v, tfidfw2v_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: At this point, X_train using all the vectorization techniques have been computed. Next is simply training the K-NNmodel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN for BoW (CountVectorizer) representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### transform X_cv using the CountVectorizer fitted on training data\n",
    "X_cv_bow = count_vectorizer.transform(X_cv.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### transform X_test using the CountVectorizer fitted on training data\n",
    "X_test_bow = count_vectorizer.transform(X_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using brute force algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get best k (hyperparameter) using brute force algorithm; tune_k also saves the knn object with best k\n",
    "k = tune_k(upper_limit = 30, X_train = X_train_bow, y_train = y_train, X_cv = X_cv_bow, y_cv = y_cv, \\\n",
    "           algorithm = 'brute', save_name = 'bow_pickles/brute_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the k-nn with best k (for brute force algorithm)\n",
    "with open('pickle_files/bow_pickles/brute_knn.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55186362323029"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using kd-tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the best k (hyperparameter) using kd-tree algorithm; tune_k also saves the knn object with best k\n",
    "k = tune_k(upper_limit = 30, X_train = X_train_bow, y_train = y_train, X_cv = X_cv_bow, y_cv = y_cv, \\\n",
    "          algorithm = 'kd_tree', save_name = 'bow_pickles/kd_tree_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the k-nn with best k (for kd_tree algorithm)\n",
    "with open('pickle_files/bow_pickles/kd_tree_knn.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55186362323029"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN for TfIdf (TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### transform X_cv using the TfidfVectorizer trained on training data\n",
    "X_cv_tfidf = tfidf_vectorizer.transform(X_cv.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### transform X_test using the TfidfVectorizer trained on training data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using brute force algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tune_k(upper_limit = 30, X_train = X_train_tfidf, y_train = y_train, X_cv = X_cv_tfidf, y_cv = y_cv, \\\n",
    "          algorithm = 'brute', save_name = 'tfidf_pickles/knn_brute.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the k-nn with best k (brute force algorithm)\n",
    "with open('pickle_files/tfidf_pickles/knn_brute.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55186362323029"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using kd_tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = tune_k(upper_limit = 30, X_train = X_train_tfidf, y_train = y_train, X_cv = X_cv_tfidf, y_cv = y_cv, \\\n",
    "          algorithm = 'kd_tree', save_name = 'tfidf_pickles/knn_kd_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the k-nn with best k (kd_tree algorithm)\n",
    "with open('pickle_files/tfidf_pickles/knn_kd_tree.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55186362323029"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. #### K-NN using Average W2V representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute average w2v represenation for X_cv\n",
    "\n",
    "X_cv_avgw2v = []\n",
    "for sentence in X_cv.ravel():\n",
    "    sum_of_words = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2v.wv:\n",
    "            continue\n",
    "        sum_of_words += w2v.wv[word]\n",
    "    X_cv_avgw2v.append(sum_of_words/len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute average w2v representation for X_test\n",
    "\n",
    "X_test_avgw2v = []\n",
    "for sentence in X_test.ravel():\n",
    "    sum_of_words = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2v.wv:\n",
    "            continue\n",
    "        sum_of_words += w2v.wv[word]\n",
    "    X_test_avgw2v.append(sum_of_words/len(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using brute force algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dd1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "k = tune_k(upper_limit = 30, X_train = X_train_avgw2v, y_train = y_train, X_cv = X_cv_avgw2v, y_cv = y_cv, \\\n",
    "          algorithm = 'brute', save_name = 'word2vec_pickles/brute_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the knn with best k (brute algo)\n",
    "\n",
    "with open('pickle_files/word2vec_pickles/brute_knn.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.55186362323029"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### K-NN using kd_tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd1\n"
     ]
    }
   ],
   "source": [
    "k = tune_k(upper_limit = 30, X_train = X_train_avgw2v, y_train = y_train, X_cv = X_cv_avgw2v, y_cv = y_cv, \\\n",
    "          algorithm = 'kd_tree', save_name = 'word2vec_pickles/kd_tree_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the knn with best k (kd_tree algo)\n",
    "\n",
    "with open('pickle_files/word2vec_pickles/kd_tree_knn.pkl', 'rb') as knn_pickle:\n",
    "    knn = pickle.load(knn_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055186362323029"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
